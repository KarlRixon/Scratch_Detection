{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据格式转化脚本\n",
    "\n",
    "#### 将voc目标检测数据转换为TFRecord格式，方便TensorFlow读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images is 1500"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "TFR_NAME = './TFR_Data/hir2019'\n",
    "IMAGE_PATH = './HIR2019/JPEGImages'\n",
    "ANNOTATION_PATH = './HIR2019/Annotations'\n",
    "SAMPLES_PER_FILES = 500\n",
    "HIR_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'scratch': (1, 'Front'),\n",
    "}\n",
    "tfr_dir = os.path.split(TFR_NAME)[0]\n",
    "if not os.path.exists(tfr_dir):\n",
    "    os.makedirs(tfr_dir)\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    raise BaseException('file {} is not exists'.format(IMAGE_PATH))\n",
    "file_names = sorted(os.listdir(IMAGE_PATH))\n",
    "random.seed = 10\n",
    "random.shuffle(file_names)\n",
    "sys.stdout.write('Number of images is {}'.format(len(file_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    \"\"\"Wrapper for inserting int64 features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    " \n",
    "def float_feature(value):\n",
    "    \"\"\"Wrapper for inserting float features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    " \n",
    "def bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting bytes features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "import re\n",
    "import linecache\n",
    "from PIL import Image\n",
    "\n",
    "def annotation_parse(image_name):\n",
    "#     tree = ET.parse(xml_path)\n",
    "#     root = tree.getroot()\n",
    "    # Image shape.\n",
    "    im = Image.open(IMAGE_PATH+'/'+image_name+'.jpg')\n",
    "    shape = [im.size[1], im.size[0], 3]\n",
    "#     size = root.find('size')\n",
    "#     shape = [int(size.find('height').text),\n",
    "#              int(size.find('width').text),\n",
    "#              int(size.find('depth').text)]\n",
    "    # Find annotations.\n",
    "    line_num = int(re.sub('\\D','',image_name))\n",
    "    line = linecache.getline('./HIR2019/train_labels.txt', line_num)\n",
    "    \n",
    "    bboxes = []\n",
    "    labels = []\n",
    "#     if 'OK' in line:\n",
    "#         return shape, bboxes, labels\n",
    "    if 'NG' in line:\n",
    "        line = line[19:-33]\n",
    "        for obj in line.split('],['):\n",
    "            labels.append(HIR_LABELS['scratch'][0])\n",
    "            \n",
    "            ymin = obj.split(',')[1]\n",
    "            xmin = obj.split(',')[0]\n",
    "            ymax = obj.split(',')[3]\n",
    "            xmax = obj.split(',')[2]\n",
    "            bboxes.append((float(ymin) / shape[0],\n",
    "                           float(xmin) / shape[1],\n",
    "                           float(ymax) / shape[0],\n",
    "                           float(xmax) / shape[1]\n",
    "                           ))\n",
    "#             bbox = obj.find('bndbox')\n",
    "#             bboxes.append((float(bbox.find('ymin').text) / shape[0],\n",
    "#                            float(bbox.find('xmin').text) / shape[1],\n",
    "#                            float(bbox.find('ymax').text) / shape[0],\n",
    "#                            float(bbox.find('xmax').text) / shape[1]\n",
    "#                            ))\n",
    "        return shape, bboxes, labels\n",
    "    else:\n",
    "        print('error')\n",
    "        exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file './TFR_Data/hir2019_000.tfrecord'......\n",
      "Writing file './TFR_Data/hir2019_001.tfrecord'......\n",
      "Writing file './TFR_Data/hir2019_002.tfrecord'......\n"
     ]
    }
   ],
   "source": [
    "num_tfr = ceil(len(file_names)/SAMPLES_PER_FILES)\n",
    "i = 0\n",
    "for idx in range(num_tfr):\n",
    "    tfr_file = '{}_{:03d}.tfrecord'.format(TFR_NAME, idx)\n",
    "    sys.stdout.write(\"Writing file '{}'......\\n\".format(tfr_file))\n",
    "    # 建立书写器\n",
    "    with tf.python_io.TFRecordWriter(tfr_file) as writer:\n",
    "        while i < SAMPLES_PER_FILES * (idx + 1) and i < len(file_names):\n",
    "            image_file = os.path.join(file_names[i].strip('.jpg'))\n",
    "            \n",
    "            line_num = int(image_file[-4:])\n",
    "            line = linecache.getline('./HIR2019/train_labels.txt', line_num)\n",
    "            i += 1\n",
    "            if 'NG' in line:\n",
    "                _, box, label = annotation_parse(image_file)\n",
    "                image_file = os.path.join(IMAGE_PATH, file_names[i])\n",
    "                image_data = tf.gfile.FastGFile(image_file, 'rb').read()\n",
    "\n",
    "                xmin, ymin, xmax, ymax = ([] for _ in range(4))\n",
    "                for b in box:\n",
    "                    assert len(b) == 4\n",
    "                    [coord.append(point) for coord, point in zip([ymin, xmin, ymax, xmax], b)]\n",
    "                image_format = b'JPEG'\n",
    "                # 建立example\n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                        'image/object/bbox/xmin': float_feature(xmin),\n",
    "                        'image/object/bbox/xmax': float_feature(xmax),\n",
    "                        'image/object/bbox/ymin': float_feature(ymin),\n",
    "                        'image/object/bbox/ymax': float_feature(ymax),\n",
    "                        'image/object/bbox/label': int64_feature(label),\n",
    "                        'image/format': bytes_feature(image_format),  # 图像编码格式\n",
    "                        'image/encoded': bytes_feature(image_data)}))  # 二进制图像数据\n",
    "                # 书写入文件\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TFRecordReader' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5ca240660932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mcommon_queue_capacity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mcommon_queue_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         shuffle=True)\n\u001b[0m\u001b[0;32m     56\u001b[0m image, glabels, gbboxes = provider.get(['image',\n\u001b[0;32m     57\u001b[0m                                         \u001b[1;34m'object/label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\data\\dataset_data_provider.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, num_readers, reader_kwargs, shuffle, num_epochs, common_queue_capacity, common_queue_min, record_key, seed, scope)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mmin_after_dequeue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommon_queue_min\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         scope=scope)\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\data\\parallel_reader.py\u001b[0m in \u001b[0;36mparallel_read\u001b[1;34m(data_sources, reader_class, num_epochs, num_readers, reader_kwargs, shuffle, dtypes, capacity, min_after_dequeue, seed, scope)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mcommon_queue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mnum_readers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_readers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         reader_kwargs=reader_kwargs).read(filename_queue)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\data\\parallel_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, reader_class, common_queue, num_readers, reader_kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mreader_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader_kwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreader_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mreader_kwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_readers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_common_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommon_queue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\data\\parallel_reader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mreader_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader_kwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreader_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mreader_kwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_readers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_common_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommon_queue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TFRecordReader' object is not callable"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "def get_split(tfr_path, tfr_pattren, num_classes=2):\n",
    "    \n",
    "    # ===============TFR文件名匹配模板===============\n",
    "    tfr_pattren = os.path.join(tfr_path, tfr_pattren)\n",
    "    \n",
    "    # =========阅读器=========\n",
    "    reader = tf.TFRecordReader()\n",
    "    \n",
    "    # ===================解码器===================\n",
    "    keys_to_features = {  # 解码TFR文件方式\n",
    "        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n",
    "        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/label': tf.VarLenFeature(dtype=tf.int64),\n",
    "    }\n",
    "    items_to_handlers = {  # 解码二进制数据\n",
    "        # 图像解码设置蛮有意思的\n",
    "        'image': slim.tfexample_decoder.Image('image/encoded', 'image/format'),\n",
    "        'object/bbox': slim.tfexample_decoder.BoundingBox(\n",
    "            ['ymin', 'xmin', 'ymax', 'xmax'], 'image/object/bbox/'),\n",
    "        'object/label': slim.tfexample_decoder.Tensor('image/object/bbox/label'),\n",
    "    }\n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "    \n",
    "    # =======描述字段=======\n",
    "    items_to_descriptions={\n",
    "        'image': 'A color image of varying height and width.',\n",
    "        'shape': 'Shape of the image',\n",
    "        'object/bbox': 'A list of bounding boxes, one per each object.',\n",
    "        'object/label': 'A list of labels, one per each object.',\n",
    "    }\n",
    "    \n",
    "    return slim.dataset.Dataset(\n",
    "            data_sources=tfr_pattren,                     # TFR文件名\n",
    "            reader=reader,                                # 阅读器\n",
    "            decoder=decoder,                              # 解码器\n",
    "            num_samples=len(file_names),       # 数目\n",
    "            items_to_descriptions=items_to_descriptions,  # decoder条目描述字段\n",
    "            num_classes=num_classes,                      # 类别数\n",
    "            labels_to_names=None                          # 字典{图片:类别,……}\n",
    "    )\n",
    "\n",
    "pattren = 'hir2019_*.tfrecord'\n",
    "dataset = get_split(tfr_dir, pattren, num_classes=2)\n",
    "provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset,  # DatasetDataProvider 需要 slim.dataset.Dataset 做参数\n",
    "        num_readers=2,\n",
    "        common_queue_capacity=20 * 5,\n",
    "        common_queue_min=10 * 5,\n",
    "        shuffle=True)\n",
    "image, glabels, gbboxes = provider.get(['image',\n",
    "                                        'object/label',\n",
    "                                        'object/bbox'])\n",
    "image, glabels, gbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                           tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    print(sess.run([glabels, gbboxes]))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def inference(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
